<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    
    <!-- Website verification -->
    <meta name="google-site-verification" content="">

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Video-Image Content Understanding | Arne Niitsoo | GenAI Specialist</title>
    <meta name="author" content="Arne  Niitsoo">
    <meta name="description" content="Engaged in a 2019 project for video-image content understanding, focused on filtering content for nudity and violence and optimizing ad targeting on a social media-like platform. Leveraged pjreddie's darknet and Yolov3 model for efficient object detection. Also tackled video-action detection, speech transcription, and automatic text summarization. Overcame challenges in limited research availability and parallel processing">
    <meta name="keywords" content="data science, machine learning, deep learning, recommendation systems, natural language processing, semantic similarity, information retrieval, large language models, LLM, computer vision, python, pytorch, tensorflow, fintech, healthtec, medtech, conversational AI">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/portfolio/work/video-content">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">Arne Niitsoo | GenAI Specialist</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Video-Image Content Understanding</h1>
            <p class="post-description">Engaged in a 2019 project for video-image content understanding, focused on filtering content for nudity and violence and optimizing ad targeting on a social media-like platform. Leveraged pjreddie's darknet and Yolov3 model for efficient object detection. Also tackled video-action detection, speech transcription, and automatic text summarization. Overcame challenges in limited research availability and parallel processing</p>
          </header>

          <article>
            <p>
  In the late summer of 2019, while I was visiting my cousins in Portland, Oregon and travelling across the west coast of USA through California I had a bit of unluck travelling between San Fransisco (SF) and San Diego (SD). As my rideshare cancelled the night before I was supposed to travel from SF-SD, I was in a bit of trouble. Looking through various options and finally as I was about to pick up a rental car the airport somebody called me and offered to pick me up and take me to LA if I am willing to drive. As we were driving, he explained the business he was building and that he might look for a ML engineer to work as a freelance contractor.
</p>

<h2 id="content-understanding">Content Understanding</h2>
<p>The platform they were working on was similar to the social media platforms such as Instagram, Snapchat or Tiktok. Users could share their images and videos with their friends or general public. These videos and videos, must be however filtered in terms of detecting nudity and violence. Furthermore, one of the key aspects of those platforms is selling ads and adtargeting.</p>

<h2 id="object-detection">Object Detection</h2>
<p>In order to do the object detection and classification, the biggest problem is related to speed. There are a lot of solutions running on the VGG, Resnet and R-CNN architecture, all of them deliver very good detection results however a quite slow when it comes to volume and speed. 
This is where, I found that the <a href="https://pjreddie.com/darknet/" target="_blank" rel="external nofollow noopener">pjreddie’s darknet</a> architecture and the pretrained model of <a href="https://www.youtube.com/watch?v=MPU2HistivI&amp;" target="_blank" rel="external nofollow noopener">Yolov3 (You-Only-Look-Once)</a> was best fit. I build a image and video classification pipeline, which ran the corresponding images through the network and yielded the most predominant objects, as they were appearing more in the image or in the video, delivered in a standard json format.</p>

<h2 id="video-action-detection">Video-Action Detection</h2>

<p><img src="https://github.com/NVlabs/STEP/blob/master/example.gif?raw=true" width="800">
<!-- <div style="text-align:center"><img src="/assets/img/projects/mlpos/6.png" width="100%"/></div> --></p>

<p>Compared to working with images/frames, detecting and classifying actions in videos is complicated. The number of parameters of these networks are huge, there is not enough data available, meaning training those models is hard. It is not as straight forward as object detection and classification in images as a lot of information comes from the temporal flow of the activities and actions happening. Luckily the <a href="https://github.com/NVlabs/STEP" target="_blank" rel="external nofollow noopener">NVIDIA-STEP</a></p>

<h2 id="speech-transcription">Speech Transcription</h2>
<p>Another interesting point for content understanding is the speech! The speech in a video gives us even more relevant information, what is the mood, the subject, the activity and more contextual knowledge of what currently is happening.</p>

<div style="text-align:center"><img src="/assets/img/projects/vidcont/2.png"></div>
<p><br></p>

<p>The big tree: Amazon, Microsoft and Google - have pretty powerful speech transcription API-s already available. I personally used Google for this part as my work platform was anyways set up using the Google Cloud Platform (GCP). 
The steps, are pretty straight forward, first extracting the audio from videos, then setting up the <a href="https://cloud.google.com/speech-to-text" target="_blank" rel="external nofollow noopener">Google Speech-to-text API</a>, which then retrives you the list of concatenated strings of the words it managed to recognize.</p>

<h2 id="automatic-text-summarization">Automatic Text Summarization</h2>
<!-- (Talk about abstractive and extractive summarization) -->
<p><a href="https://arxiv.org/abs/1904.00688" target="_blank" rel="external nofollow noopener">Automatic text summarization </a> is the next big thing in content understanding. Essentially what we want to do is to extract the audio from the video and now using the speech transcription, we get messy composition of words, which might look chaotic. The two different approaches, <a href="https://arxiv.org/pdf/1909.03186.pdf" target="_blank" rel="external nofollow noopener">abstractive and extractive summarization</a> try to make sense of the context. We can think of extractive summarization as a highlighter pen, where we highlight the most meaningful parts. Whereas, abstractive summarization aims to summarize the text more like a human, i.e. generating new sentences from the input text.</p>

<h2 id="challenges">Challenges</h2>
<p>The hardest part about this project was definetly getting the hang of video-action detection part. There is a lot of research done recently and some of the work is publicly available, while the most powerful models either were in the process of being published or waiting to be accepted to the conferences.
Another big challenge was making it all run in an parallel manner. This meant that first the audio had to be extracted from the video, then the video converted into images, which was then fed into object detection pipeline and action-detection pipeline at the same time. Using multiprocessing and some designs tricks, all the processes could be ran in parallel.</p>

<div style="text-align:center"><img src="/assets/img/projects/vidcont/1.jpg"></div>
<p><br></p>

<p>Check out more at <a href="https://video.io" target="_blank" rel="external nofollow noopener">this page.</a></p>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2024 Arne  Niitsoo. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.
Last updated: January 27, 2024.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-177262811-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-177262811-1');
  </script><!-- Cronitor RUM -->
<script async src="https://rum.cronitor.io/script.js"></script>
<script>
    window.cronitor = window.cronitor || function() { (window.cronitor.q = window.cronitor.q || []).push(arguments); };
    cronitor('config', { clientKey: '0becbec9d8fd010afa6a15bd679b2300' });
</script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
